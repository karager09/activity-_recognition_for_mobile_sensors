{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to extract data from sqlite database.\n",
    "Database was downloaded from smartphone using android backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(db_file):\n",
    "    import sqlite3\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT * FROM accelerometer_data\")\n",
    "        rows = cur.fetchall()\n",
    "        conn.close()\n",
    "        return rows\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data_from_file('../accelerometer_data.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coor_x</th>\n",
       "      <th>coor_y</th>\n",
       "      <th>coor_z</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.381454</td>\n",
       "      <td>4.313154</td>\n",
       "      <td>8.368932</td>\n",
       "      <td>1575470973260</td>\n",
       "      <td>WALKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.183156</td>\n",
       "      <td>5.242105</td>\n",
       "      <td>11.680113</td>\n",
       "      <td>1575470973393</td>\n",
       "      <td>WALKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.823605</td>\n",
       "      <td>2.134431</td>\n",
       "      <td>8.748413</td>\n",
       "      <td>1575470973527</td>\n",
       "      <td>WALKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.882263</td>\n",
       "      <td>2.390610</td>\n",
       "      <td>6.970718</td>\n",
       "      <td>1575470973660</td>\n",
       "      <td>WALKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.363919</td>\n",
       "      <td>4.357447</td>\n",
       "      <td>7.726089</td>\n",
       "      <td>1575470973795</td>\n",
       "      <td>WALKING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coor_x    coor_y     coor_z      timestamp activity\n",
       "0  1.381454  4.313154   8.368932  1575470973260  WALKING\n",
       "1  0.183156  5.242105  11.680113  1575470973393  WALKING\n",
       "2 -0.823605  2.134431   8.748413  1575470973527  WALKING\n",
       "3  0.882263  2.390610   6.970718  1575470973660  WALKING\n",
       "4 -0.363919  4.357447   7.726089  1575470973795  WALKING"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data, columns = ['id', 'coor_x', 'coor_y', 'coor_z', 'timestamp', 'activity'])\n",
    "df = df.drop(columns = ['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#normalise\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[['coor_x', 'coor_y', 'coor_z']] = scaler.fit_transform(df[['coor_x', 'coor_y', 'coor_z']])\n",
    "x_data = df[['coor_x', 'coor_y', 'coor_z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') #the ROCKET project is in parent directory\n",
    "\n",
    "from rocket_master.code.rocket_functions import generate_kernels, apply_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73973445, -0.14256561,  0.1948192 , -0.70367441, -0.78927959,\n",
       "        0.65520331,  0.67094386, -0.12138162, -0.5037996 ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate random kernels\n",
    "kernels = generate_kernels(input_length = x_data.shape[1], num_kernels = 10_000)\n",
    "kernels[0][100] #example kernel, in form: weights, lengths, biases, dilations, paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.75877717, 1.        , ..., 0.31798007, 1.        ,\n",
       "       0.74093289])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_transformed = apply_kernels(x_data.to_numpy(), kernels)\n",
    "x_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split data for train and test dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_transformed, df[['activity']], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "       2.15443469e+02, 1.00000000e+03]),\n",
       "                  class_weight=None, cv=None, fit_intercept=True,\n",
       "                  normalize=True, scoring=None, store_cv_values=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10), normalize = True)\n",
    "classifier.fit(x_train, y_train.to_numpy().ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy    = 0.6601941747572816\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "# print(f\"predictions = {', '.join(predictions.astype(str))}\")\n",
    "print(f\"accuracy    = {(predictions == y_test['activity']).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check when predictions are wrong\n",
    "test_df = pd.DataFrame(y_test[predictions != y_test['activity']])\n",
    "test_df['predicted'] = predictions[predictions != y_test['activity']]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model predictions are pretty good (about 60/70 %).\n",
    "We should remember, that very small dataset was used (also with some mistakes), as well as the raw data was loaded - we could have group it into eg. 3-seconds frames, but it wouldn't be apropriate for ROCKET.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
